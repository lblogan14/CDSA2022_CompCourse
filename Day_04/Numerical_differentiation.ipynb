{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Numerical_differentiation.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_5evX44xyk0"
      },
      "source": [
        "# Numerical Differentiation and Machine Error "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb7jXFyKxyk4"
      },
      "source": [
        "Throughout physics, we need to be able to take derivatives of functions and data. However, this process can introduce large errors so we need to procede carefully.\n",
        "\n",
        "## Learning objectives\n",
        "\n",
        "After this lesson, you should be able to:\n",
        "* Compute a numerical derivative using forward/backward differentiation\n",
        "* Be able to use different stencils\n",
        "* Compare two floating point numbers\n",
        "* Evaluate and communicate the numerical error resulting from performing differentiation discretely"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiiQUx8wxyk5"
      },
      "source": [
        "## Derivatives\n",
        "\n",
        "Estimating the derivative of a function is a very common task in scientific computing. The need arises, for example, when \n",
        "we have data that represent some dependent variable $f$ as a function of an independent variable $x$, and we would like \n",
        "to know the rate at which $f$ changes. If the data are generated from a numerical code, or from an experiment, then $f$ is \n",
        "only known at discrete \n",
        "values of $x$ and we cannot differentiate $f(x)$ analytically. We must resort to numerical techniques. \n",
        "\n",
        "Numerical differentiation can be difficult to do well. We cannot apply the definition \n",
        "\n",
        "$$\n",
        "\\label{derivativedef}\n",
        "f'(x)  = \\lim_{h\\to 0}\\frac{f(x+h)-f(x)}{h} \n",
        "\\tag{1}\n",
        "$$\n",
        "\n",
        "directly if the data are discrete, because we cannot take the limit $h\\to 0$. Even in cases where we can evaluate the \n",
        "function everywhere, this expression for the derivative is prone to an error known as _subtractive cancellation_.  Subtractive cancellation occurs if you make $h$ very small, as the definition requires. \n",
        "\n",
        "Consider for example the function $f(x) = \\cos(x)\\tanh(x)$. You can verify that it's derivative at $x=2$ is\n",
        "\n",
        "$$\n",
        "\tf'(2) = \\cos(2){\\rm sech}^2(2) - \\sin(2)\\tanh(2) \\approx -0.905989\n",
        "$$\n",
        "\n",
        "However, if we use the definition (1) with $h = 10^{-16}$, the result in double precision is \n",
        "\n",
        "$$\n",
        "\tf'(2) = \\frac{f(2+h) - f(2)}{h} = 0.0\n",
        "$$\n",
        "\n",
        "The answer is wrong because with double precision both $f(2+h)$ and $f(2)$ evaluate to $-0.40117702779274822$.  \n",
        "With single precision, subtractive cancellation occurs for much larger values of $h$. \n",
        "\n",
        "## Why is this? How variables are stored.\n",
        "\n",
        "Computer represent all numbers as strings of bits. For integers, this is straightforward:\n",
        "\n",
        "    1 = 0001\n",
        "    2 = 0010\n",
        "    3 = 0011\n",
        "\n",
        "etc. For floating point numbers (decimals), life is a little bit harder.  To get an idea of how this works, try out this interactive tool:\n",
        "\n",
        "http://evanw.github.io/float-toy/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fMJL2q0xyk5"
      },
      "source": [
        "## Forward and Backward Difference Formulas\n",
        "\n",
        "\n",
        "The definition (1) for the derivative $f'(x)$ requires us to evaluate the function \n",
        "at two points, namely, $x+h$ and $x$. We need to develop techniques to *approximate the derivative $f'(x)$ \n",
        "that do not require us to take the limit $h\\to 0$. The approximations to $f'(x)$ are constructed from \n",
        "combinations of the function $f$ evaluated at various points surrounding $x$. We refer to these as *finite \n",
        "difference* formulas. \n",
        "\n",
        "Let's say we want to approximate $f'(x)$ using the \n",
        "values of $f$ at the points $x$ and $x+h$. That is, we want a formula that says \n",
        "\n",
        "$$\n",
        "\\label{fprimeab}\n",
        "f'(x) \\approx a f(x+h) + b f(x) \n",
        "\\tag{2}\n",
        "$$\n",
        "\n",
        "for some constants $a$ and $b$. We can determine $a$ and $b$ by using the Taylor series\n",
        "\n",
        "$$\n",
        "\tf(x+h) = f(x) + f'(x) h + \\frac{1}{2} f''(x) h^2 + \\cdots\n",
        "$$\n",
        "\n",
        "to expand the right--hand side of Eq.(2). This yields \n",
        "\n",
        "$$\n",
        "\\label{afbfexpanded}\n",
        "\ta f(x+h) + b f(x)  = (a+b)f(x) + a f'(x) h + \\frac{a}{2} f''(x) h^2 + \\cdots\n",
        "\\tag{3}\n",
        "$$\n",
        "\n",
        "The right--hand side of this relation will equal $f'(x)$, approximately, if $a+b=0$ and $a=1/h$. (That is, $a=1/h$ and $b=-1/h$.) \n",
        "With these values for the constants, Eq.(2) yields \n",
        "\n",
        "$$\n",
        "\\label{forwarddiffformula}\n",
        "\tf'(x) \\approx \\frac{f(x+h) - f(x)}{h}\n",
        "\\tag{4}\n",
        "$$\n",
        "\n",
        "This approximation to the first derivative is called the _forward difference_. It is simply the \n",
        "definition (1) without the limit $h \\to 0$.\n",
        "\n",
        "Let's look at this result a bit more closely. With $a=1/h$ and $b=-1/h$, Eq.(3)\n",
        "becomes \n",
        "\n",
        "$$\n",
        "\t\\frac{1}{h} f(x+h) - \\frac{1}{h} f(x) = f'(x) + \\frac{1}{2} f''(x) h + \\cdots\n",
        "$$\n",
        "\n",
        "Equivalently, we can write this as\n",
        "\n",
        "$$\n",
        "\\label{fdwitherr}\n",
        "\tf'(x) = \\frac{f(x+h) - f(x)}{h} - \\frac{1}{2} f''(x) h + \\cdots\n",
        "\\tag{5}\n",
        "$$\n",
        "\n",
        "This shows that the error in the forward difference approximation (5) is\n",
        "\n",
        "$$\n",
        "\\label{EFexpression}\n",
        "\t{\\cal E}_F = \\frac{1}{2} f''(x) h + \\cdots\n",
        "$$\n",
        "\n",
        "In particular, the leading term in ${\\cal E}_F$ is proportional to $h$.\n",
        "\n",
        "We can carry out a similar analysis to obtain a finite difference approximation to \n",
        "$f'(x)$ using the points $x-h$ and $x$. \n",
        "The result is the _backward difference_ approximation\n",
        "\n",
        "$$\n",
        "\\label{backwarddiffformula}\n",
        "\tf'(x) \\approx \\frac{f(x) - f(x-h)}{h}\n",
        "$$\n",
        "\n",
        "with error \n",
        "$$\n",
        "\\label{EBexpression}\n",
        "\t{\\cal E}_B = -\\frac{1}{2} f''(x) h + \\cdots \n",
        "$$\n",
        "\n",
        "Again, the leading term in the error is proportional to $h$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sxNqzsuxyk6"
      },
      "source": [
        "## Exercise 1: \n",
        "\n",
        "Write a code to compute the forward and backward difference approximations to $f'(2.0)$, where \n",
        "$f(x) =  \\cos(x)\\tanh(x)$. Use $h = 10^{-1}, 10^{-2},\\ldots,10^{-7}$. For both approximation methods, show that the errors ${\\cal E}$ are \n",
        "proportional to $h$ in one of two ways:\n",
        "\n",
        "1. Show that a log--log plot of ${\\cal E}$ versus $h$ gives a straight \n",
        "line with slope $1$. \n",
        "\n",
        "2. If the error is proportional to $h$, then ${\\cal E} = C h$ for some constant $C$. \n",
        "Let $h_1$ and $h_2$ denote your two smallest $h$ values, and ${\\cal E}_1$ and ${\\cal E}_2$ denote the corresponding \n",
        "errors. The relations ${\\cal E}_1 = C h_1$ and ${\\cal E}_2 = C h_2$ imply ${\\cal E}_2/{\\cal E}_1 = h_2/h_1$. If the \n",
        "ratio ${\\cal E}_2/{\\cal E}_1$ agrees (approximately) with the ratio $h_2/h_1$, then the errors are proportional to $h$.\n",
        "\n",
        "**New command for today: numpy.zeros_like() -- it produces an array of zeros of the same shape as the one you give it.  So, for 1D arrays, it's equivalent to numpy.zeros(len(A)), where A is your reference array.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gNfD2QVxyk6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import mpmath as mp\n",
        "import pylab as py\n",
        "\n",
        "# Define the function to be finite-differentiated\n",
        "def funCT(x):\n",
        "    return np.cos(x)*np.tanh(x)\n",
        "\n",
        "def sech(x):\n",
        "  return 2.0/(np.exp(x)+ np.exp(-x))\n",
        "\n",
        "# Define the analytical answer\n",
        "def derivCT(x):\n",
        "    return np.cos(x)*sech(x)**2-np.sin(x)*np.tanh(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) show that the log-log plot of error-h gives a straight line with slope 1\n",
        "h = 10.**np.arange(-7,0,1) # grid resolution\n",
        "print(h)\n",
        "N = len(h)\n",
        "\n",
        "errFD = np.zeros_like(h)  # create array for errors of forward diff\n",
        "errBD = np.zeros_like(h) # create array for errors of backward diff\n",
        "\n",
        "x = 2. # point where we evaluate derivative\n",
        "\n",
        "# Calculate errors for FFD and BFD. Use absolute number for log plot\n",
        "for i in range(N):\n",
        "    errFD[i] = np.absolute(derivCT(x) - (funCT(x + h[i]) - funCT(x))/h[i]) # FFD\n",
        "    errBD[i] = np.absolute(derivCT(x) - (funCT(x) - funCT(x - h[i]))/h[i]) # BFD\n",
        "\n",
        "# Plot the result\n",
        "py.plot(np.log10(h), np.log10(errFD),'>-', label='forward diff')\n",
        "py.plot(np.log10(h), np.log10(errBD),'<-', label='backward diff')\n",
        "py.plot(np.log10(h), np.log10(h), '--k', label='$\\propto h$')\n",
        "py.xlabel('$\\log_{10}(h)$')\n",
        "py.ylabel('$\\log_{10}(\\cal E)$')\n",
        "py.legend()\n",
        "py.show()\n",
        "\n",
        "# 2) if the error is propotional to h, the ratio for the last two elements of\n",
        "# FD should agree with hGD ratio\n",
        "\n",
        "hRatio = np.zeros(N-1) # ratio for FFD\n",
        "errRatioF= np.zeros_like(hRatio) # ratio for FFD\n",
        "errRatioB= np.zeros_like(hRatio) # ratio for BFD\n",
        "\n",
        "for i in range(1,N):\n",
        "    hRatio[i-1] = h[i]/h[i-1]\n",
        "    errRatioF[i-1]= errFD[i]/errFD[i-1] \n",
        "    errRatioB[i-1]= errBD[i]/errBD[i-1] \n",
        "\n",
        "# Plot the ratio\n",
        "py.plot(errRatioF,'>', label='forward')\n",
        "py.plot(errRatioB,'<', label='backward')\n",
        "py.plot(hRatio, '--k', label='h ratio')\n",
        "py.xlabel('i')\n",
        "py.legend()\n",
        "#py.ylim([0,0.2])\n",
        "py.show()"
      ],
      "metadata": {
        "id": "lJU0a8w226yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqmv_k5Rxyk7"
      },
      "source": [
        "## Machine Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Eg46rL_xyk7"
      },
      "outputs": [],
      "source": [
        "#Computers represent numbers in a binary floating point format with a fixed number of bits.  \n",
        "#This means that you have some limitation in how many digits your computer can represent.\n",
        "#For example, try the following:\n",
        "\n",
        "print(0.1+0.2)\n",
        "print(0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfYXwzlSxyk8"
      },
      "outputs": [],
      "source": [
        "# This means that statements you *think* are true sometimes are not:\n",
        "a = 0.1 + 0.2\n",
        "b = 0.3\n",
        "\n",
        "if a==b:\n",
        "    print(\"a and b are the same!\")\n",
        "else:\n",
        "    print(\"a and b are different\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m58KXf6hxyk8"
      },
      "outputs": [],
      "source": [
        "# Aside from the numerical error you saw above in trying to use numbers h that are too small,\n",
        "# the biggest place you'll have to pay attention is in comparisons such as the one above.  The correct\n",
        "# way to do this is by comparing the absolutel value of the difference to a small number: |a - b| < tolerance\n",
        "\n",
        "a = 0.1 + 0.2\n",
        "b = 0.3\n",
        "\n",
        "if abs(a-b) < 1e-10:\n",
        "    print(\"a and b are the same!\")\n",
        "else:\n",
        "    print(\"a and b are different\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ilHYN3Qxyk8"
      },
      "source": [
        "You can find some more reading on floating point error here:\n",
        "* http://www.lahey.com/float.htm\n",
        "* https://docs.python.org/3/tutorial/floatingpoint.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyU0i4fsxyk9"
      },
      "source": [
        "## Central Difference Formula\n",
        "\n",
        "Let's derive a finite difference approximation for $f'(x)$ using the _three_ points $x-h$, $x$ and $x+h$. \n",
        "That is, we seek a relation \n",
        "\n",
        "$$\n",
        "\tf'(x) \\approx a f(x-h) + b f(x) + c f(x+h)\n",
        "    \\tag{8}\n",
        "$$\n",
        "\n",
        "for some constants $a$, $b$ and $c$. The contants are determined by expanding $f(x-h)$ and $f(x+h)$ in Taylor series\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\tf(x-h) & = f(x) - f'(x) h + \\frac{1}{2} f''(x) h^2 - \\frac{1}{6} f'''(x) h^3 + \\cdots  \\\\\n",
        "\tf(x+h) & = f(x) + f'(x) h + \\frac{1}{2} f''(x) h^2 + \\frac{1}{6} f'''(x) h^3 + \\cdots \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "and inserting these into the right--hand side of Eq. (8):\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\ta f(x-h) + b f(x) + c f(x+h) & =  (a + b + c)f(x) + (c-a)f'(x) h + \\frac{1}{2}(c+a)f''(x) h^2 \\ \\\\\n",
        "\t&  \\quad + \\frac{1}{6}(c-a)f'''(x) h^3 + \\cdots\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This expression will equal $f'(x)$, approximately, if \n",
        "\n",
        "$$\n",
        "(a+b+c) = 0, \\\\\n",
        "(c-a) = 1/h, \\\\\n",
        "(c+a) = 0. \n",
        "$$\n",
        "\n",
        "That is, $a = -1/(2h)$, $b=0$, and $c=1/(2h)$. With these values for the constants, we have \n",
        "\n",
        "$$\n",
        "\t-\\frac{1}{2h} f(x-h) + \\frac{1}{2h} f(x+h) = f'(x) + \\frac{1}{6} f'''(x) h^2 + \\cdots\n",
        "$$\n",
        "\n",
        "This gives us the __central difference__ formula for the first derivative:\n",
        "\n",
        "$$\n",
        "\tf'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h} \n",
        "$$\n",
        "\n",
        "The error for this method is \n",
        "\n",
        "$$\n",
        "\t{\\cal E}_C = \\frac{1}{6} f'''(x) h^2 + \\cdots\n",
        "$$\n",
        "\n",
        "It is proportional to $h^2$. \n",
        "\n",
        "The central difference formula is simply the average of the forward and \n",
        "backward difference formulas. In taking the average, the order $h$ terms in the errors ${\\cal E}_F$ and ${\\cal E}_B$ \n",
        "cancel. The order $h^2$ terms, included in the $\\cdots$ of Eqs.(6) and (7), do not \n",
        "cancel; rather, they combine to give the central difference error ${\\cal E}_C$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3sq0tjmxyk9"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Numerically-compute the derivative of $f(x) = \\cos(x)\\tanh(x)$ at $x=2$ using the central difference method. Using a graph, show that the error ${\\cal E}$ is proportional to $h^2$, by comparing to the value you know from calculus. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVtW8UR_xyk9"
      },
      "outputs": [],
      "source": [
        "h = 10.**(-np.arange(1,8,0.5)) # grid resolution\n",
        "#print(h)\n",
        "N = len(h)\n",
        "\n",
        "errCD = np.zeros_like(h)  # create array for errors of forward diff\n",
        "errFD = np.zeros_like(h) # create array for errors of backward diff\n",
        "\n",
        "x = 2. # point where we evaluate derivative\n",
        "\n",
        "# Calculate derivatives\n",
        "for i in range(N):\n",
        "    errCD[i]= np.abs(derivCT(x) - (funCT(x + h[i]) - funCT(x - h[i]))/(2*h[i]))/np.abs(derivCT(x)) # Central\n",
        "    errFD[i]= np.abs(derivCT(x) - (funCT(x + h[i]) -funCT(x))/h[i])/np.abs(derivCT(x)) # Forward\n",
        "    \n",
        "# Plot the result: the slope is 2h in log plot, corresponding to h^2 error.\n",
        "#py.plot(np.log10(h), np.log10(errFD),'>-', label='forward diff')\n",
        "py.plot(np.log10(h), np.log10(errCD),'^-g', label='central diff - actual')\n",
        "py.plot(np.log10(h), np.log10(h**2), '--k', label='$\\propto h^2$')\n",
        "py.xlabel('$\\log_{10}(h)$')\n",
        "py.ylabel('$\\log_{10}(\\cal E)$')\n",
        "py.legend()\n",
        "\n",
        "py.figure(2)\n",
        "py.plot(h**2,errCD)\n",
        "py.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(h)"
      ],
      "metadata": {
        "id": "SGSK3MXB3afx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The other way to show it\n",
        "hRatio = np.zeros(N-1) # for plot\n",
        "errRatioC= np.zeros(N-1) # ratio for FFD\n",
        "\n",
        "for i in range(1,N):\n",
        "    hRatio[i-1] = h[i]/h[i-1]\n",
        "    errRatioC[i-1]= errCD[i]/errCD[i-1] \n",
        "\n",
        "# Plot the ratio\n",
        "py.plot(errRatioC,'o', label='error ratio')\n",
        "py.plot(hRatio**2, '--k', label='(h ratio)^2')\n",
        "py.xlabel('index')\n",
        "py.ylabel('ratio')\n",
        "py.legend()\n",
        "py.show()"
      ],
      "metadata": {
        "id": "dLYZ7Lel3cUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwlv7t8Pxyk9"
      },
      "source": [
        "Other stencils\n",
        "--------------------\n",
        "The pattern of evaluation points and coefficients is sometimes referred to as the \"stencil\". For example, the forward difference \n",
        "formulae might be called a one-sided, two-point stencil. The central difference formula \n",
        "is a centered, three-point stencil (although the coefficient of one of those points is zero). \n",
        "\n",
        "The method of the preceeding sections can be used to obtain other stencils for $f'(x)$. For example, we might \n",
        "want to calculate the derivative without any function evaluations at points less than $x$. For this we can choose \n",
        "a three-point stencil consisting of the points $x$, $x+h$ and $x+2h$. Using the Taylor series expressions \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\tf(x+h) & = & f(x) + f'(x) h + \\frac{1}{2} f''(x) h^2 + \\frac{1}{6} f'''(x) h^3 + \\cdots \\\\\n",
        "\tf(x+2h) & = & f(x) + 2 f'(x) h + \\frac{4}{2} f''(x) h^2 + \\frac{8}{6} f'''(x) h^3 + \\cdots\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "we have \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\ta f(x) + b f(x+h) + c f(x+2h) & =   (a + b + c) f(x) + (b + 2c) f'(x) h \\\\\n",
        "\t & + \\frac{1}{2} (b + 4c) f''(x) h^2  + \\frac{1}{6} (b + 8c) f'''(x) h^3 + \\cdots\n",
        "\\end{aligned}\n",
        "\\tag{9}   \n",
        "$$\n",
        "\n",
        "This will approximate $f'(x)$ if the coefficients satisfy\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "(a + b + c) & = & 0 \\\\\n",
        "\t(b + 2c)h & = & 1 \\\\\n",
        "\t(b + 4c) & = & 0 \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The solution is $a = -3/(2h)$, $b = 2/h$, $c = -1/(2h)$. This yields the finite difference formula\n",
        "\n",
        "$$\n",
        "f'(x) \\approx \\frac{-3f(x) + 4f(x+h) - f(x+2h)}{2h}\n",
        "\\tag{10}\n",
        "$$\n",
        "\n",
        "The terms $(b+8c)f'''(x) h^3/6 + \\cdots$ from Eq.(9), which are order $h^2$, do not vanish. Thus, the error \n",
        "for this one-sided, three-point stencil is proportional to $h^2$. \n",
        "\n",
        "\n",
        "\n",
        "In general, derivative formulas that use large stencils have higher order error. (That is, the error is a higher \n",
        "power of $h$.) However, derivative formulas with large stencils are more susceptible to subtractive cancellation errors. \n",
        "Thus, a stencil with a very high order error is not always accurate. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEpEgCx2xyk9"
      },
      "source": [
        "\n",
        "## Exercise\n",
        "\n",
        "First, make sure that you understand the three-point stencil derivation, above. If you get stuck on this problem, you can use the three-point stencil (first) and then come back later to update it to being a five-point stencil.\n",
        "\n",
        "a) Determine the five-point centered stencil for $f'(x)$: this stencil is like the three-point stencil in Eq. 10, but spans the points $x-2h$, $x-h$, $x$, $x+h$, $x+2h$. You may use Mathematica or Maple to solve for the constants, or ask for help to get them. Write your equations in a similar form to the three-point stencil above. \n",
        "\n",
        "b) Numerically-compute the derivative of $f(x) = \\cos(x)\\tanh(x)$ at $x=2$ using this five-point stencil. Using a graph, show that the error ${\\cal E}$ is proportional to $h^4$, by comparing to the value you know from calculus. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh-Jn2NSxyk9"
      },
      "outputs": [],
      "source": [
        "h = 10**(-np.arange(1,8,.5)) # grid resolution\n",
        "print(h)\n",
        "\n",
        "err5CD = np.zeros_like(h) # create array for errors of 5-point CD\n",
        "err3CD = np.zeros_like(h) # create array for errors of 3-point CD\n",
        "\n",
        "x = 2. # point where we evaluate derivative\n",
        "\n",
        "for i in range(len(h)):\n",
        "    err5CD[i]= np.absolute((derivCT(x) - \n",
        "                           (funCT(x - 2*h[i]) - 8*funCT(x - h[i]) \n",
        "                            + 8*funCT(x + h[i]) - funCT(x + 2*h[i]))/(12*h[i]))/derivCT(x))*100\n",
        "    err3CD[i]= np.absolute(derivCT(x) - \n",
        "                           (funCT(x + h[i]) - funCT(x - h[i]))/(2*h[i])) \n",
        "\n",
        "# Plot the result\n",
        "#py.plot(np.log(h), np.log(err5CD),'o-m', label='5-point CD')\n",
        "#py.plot(np.log(h), np.log(h**4), 'm--', label='$h^4$')\n",
        "py.plot(np.log10(h), np.log10(err3CD),'^-g', label='3-point CD')\n",
        "py.plot(np.log10(h[2:]), np.log10(h[2:]**2), 'g--', label='$h^2$')\n",
        "py.legend()\n",
        "py.xlabel('$\\log_{10}(h)$')\n",
        "py.ylabel('$\\log_{10}(\\cal E)$')\n",
        "\n",
        "py.figure(2)\n",
        "py.plot(h**4,err5CD,'-')\n",
        "py.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (np.log10(h))\n",
        "print (np.log(err5CD))"
      ],
      "metadata": {
        "id": "u9RddODa3uSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFg8vR1Jxyk-"
      },
      "source": [
        "## Second derivatives\n",
        "\n",
        "We can apply the same technique to derive finite difference stencils for second derivatives, $f''(x)$, as well as higher order \n",
        "derivatives. For example, consider the three-point centered stencil for $f''(x)$. We can derive this stencil by\n",
        "examining the Taylor expansion:\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\ta f(x-h) + b f(x) + c f(x+h) & =  (a + b + c)f(x) + (c-a)f'(x) h + \\frac{1}{2}(c+a)f''(x) h^2  \\\\\n",
        "\t&  \\quad + \\frac{1}{6}(c-a)f'''(x) h^3 + \\cdots\n",
        "\\end{aligned}\n",
        "    \\tag{11}\n",
        "$$\n",
        "\n",
        "The right-hand side will approximate $f''(x)$ if $(a+b+c)=0$, $(c-a)=0$ and $(c+a) h^2/2 = 1$. This gives \n",
        "$a = 1/h^2$, $b = -2/h^2$ and $c = 1/h^2$, so that\n",
        "\n",
        "$$\n",
        "\t\\frac{1}{h^2} f(x-h) - \\frac{2}{h^2} f(x) + \\frac{1}{h^2} f(x+h) = f''(x) + \\cdots\n",
        "$$\n",
        "\n",
        "Thus, the centered three-point stencil for the second derivative is \n",
        "\n",
        "$$\n",
        "\tf''(x) \\approx \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}\n",
        "    \\tag{12}\n",
        "$$\n",
        "\n",
        "Note that the term $(c-a)f'''(x) h^3/6$ in Eq.(11) vanishes for the chosen values of \n",
        "$a$, $b$ and $c$. The next order term in Eq.(11) is proportional to $(c+a) f''''(x) h^4$. This term does not vanish and is proportional to $h^2$. Thus, the error for the formula (12) is of order $h^2$. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-yPV-VIxyk-"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "a) Numerically-compute the second derivative of $f(x) = \\ln(x)/\\cosh(x)$ for $2.0 \\le x \\le 5.0$, using the three-point centered stencil (Eq. 12). Plot a graph of $f''(x)$ over this range. \n",
        "\n",
        "b) Consider this graph: what features (limits? max? min? other comparisons?) can you explain using mathematics, that give you confidence in your result?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmsbwxiYd6YX"
      },
      "outputs": [],
      "source": [
        "def funLC(x):\n",
        "    return np.log(x) / mp.cosh(x)\n",
        "\n",
        "def fppLC(x):\n",
        "    return -mp.sech(x)*(-x*x*np.log(x)*mp.tanh(x)*mp.tanh(x) + x*x*np.log(x)*mp.sech(x)*mp.sech(x) + 2*x*mp.tanh(x) +1) /x**2\n",
        "\n",
        "# Variables\n",
        "h = 0.001  #pick a reasonable grid spacing (not too small, not too large)\n",
        "xarray= np.linspace(2, 5, 300) # x-axis: 300 points from 2 to 5\n",
        "f = np.zeros_like(xarray)\n",
        "fpp3CD = np.zeros_like(xarray) # the second derivative for funLC using the three-point CFD\n",
        "fpp = np.zeros_like(xarray) # for analytical answer\n",
        "\n",
        "# CFD\n",
        "for ix, x in enumerate(xarray):\n",
        "    f[ix] = funLC(x)\n",
        "    fpp3CD[ix] = (funLC(x+h) + funLC(x-h) - 2*funLC(x))/h**2\n",
        "    fpp[ix] = fppLC(x)\n",
        "\n",
        "# the function\n",
        "py.plot(xarray, f,'-b')\n",
        "py.xlabel('$x$')\n",
        "py.ylabel('$f(x)$')\n",
        "py.show()\n",
        "    \n",
        "# the second derivative\n",
        "py.plot(xarray, fpp3CD,'-r', label='3-point centered stencil')\n",
        "py.plot(xarray, fpp ,'--k', label='analytic')\n",
        "py.xlabel('$x$')\n",
        "py.ylabel('$f^{\\prime \\prime}(x)$')\n",
        "py.legend()\n",
        "py.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q3LFXuOi3z0G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}