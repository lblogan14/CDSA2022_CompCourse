{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Curve_Fitting.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3xHClVclP-Q"
      },
      "source": [
        "# Module 13: Data & Curve fitting\n",
        "\n",
        "In physics, we often a physical model in mind, for how we expect our data to behave or for how we want to analyze it. In order to make a comparison between the model abd our data, we need to be able to load data into Python (rather than generating it within Python). Many data analysis packages are available inside SciPy which help ease the task of understanding data.\n",
        "\n",
        "*Note:* Please complete these activities on your own computer or on JHub, where you have full control of where the files are placed within your path (filesystem). Google Colab is difficult to use in this context.\n",
        "\n",
        "## Learning objectives\n",
        "* Learn how to import data from elsewhere\n",
        "* Learn how to extract something useful from the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XANAmcIwlP-V"
      },
      "source": [
        "## Reading and writing text data files\n",
        "\n",
        "Often, an experimental apparatus will be controlled by a computer; the data from the experiment is often saved in an ASCII plain text file, with numbers separated by spaces, commas, or tabs. The data is often organized in rows or columns, like you might see in a spreadsheet. Common suffixes for these files are `.txt` or `.csv` (comma-separated variables). A nice feature of ASCII files is that they can be opened by any software, including software that you write yourself. \n",
        "\n",
        "Particularly when these data files are large and/or numerous, it is preferable to have a data-anlysis program read the data directly from a file. This also allows you to batch-process many files using the same Python script, rather than having to do perform each analysis by hand. \n",
        "\n",
        "Reading data from a file and writing data to a file can be a bit tricky, because Python interprets each character, including spaces and carriage returns, quite literally. For scientific purposes, we usually want to read and write arrays of floating point (real) numbers, but reading text characters is also useful, particularly in biophysics, geophysics, and astrophysics where the names of proteins, geographic locations, and astronomical objects might be part of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuo1m-MclP-W"
      },
      "source": [
        "###  numpy tools\n",
        "\n",
        "As you might already expect, `numpy` includes easy-to-use functions for reading and writing data arrays. Two of these functions are called `loadtxt()` and `savetxt()`. \n",
        "\n",
        "To load the contents of the file  *filename* into the array variable `a`, simply use:\n",
        "\n",
        "    a = np.loadtxt(filename) \n",
        "\n",
        "To save the array `a` to a file, just write:\n",
        "\n",
        "    np.savetxt(filename, a) \n",
        "\n",
        "\n",
        "There are optional arguments to `loadtxt()` and `savetxt()` that you should explore on your own. By default, \n",
        "`loadtxt()` and `savetxt()` assume all numbers are real (type `float`). \n",
        "\n",
        "Note that `loadtxt` will give you a 2D array with the number of rows and columns corresponding to the rows and columns in the file.  Recall that to get a single column out of a 2D array, you slice it using `a[:,column_index]`.\n",
        "\n",
        "Two other useful `numpy` file-readers are:\n",
        "* `genfromtxt()` (has some nice features if the file has missing numbers)\n",
        "* `read_csv()` (if you know the file has comman-separated variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ-ljLTulP-W"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Download the file `damped_oscillation.txt` from the Google Drive, and place it into the same directory where you saved the Jupyter notebook, using the commands listed above.\n",
        "\n",
        "Note that, unless you specify a full file path, Python will assume that the file *filename* is in the same directory as the program you a running.  You may have to experiment with the precise file path, since it will depend on the machine you're running on, and where you saved the files. Typically, `loadtxt('damped_oscillation.txt')` should work, but here are some other things to try out. \n",
        "\n",
        "*If you need to use the full path:* be sure get the correct spelling and punctuation, and not the the direction the slashes face depends on which operating system you are using. Doing a copy-paste from from your file browser is a good way not to make typos. Here are some examples of what this might look like on different operating systems:\n",
        "* Windows: `C:\\\\Documents\\username\\sub\\directory\\damped_oscillation.txt` (note the double backslash)\n",
        "* Mac: `/Users/username/sub/directory/damped_oscillation.txt`\n",
        "* Linux: `/home/username/sub/directory/damped_oscillation.txt`\n",
        "\n",
        "Once you have no error on the file-loading (the first cell), you are ready to access the data (the second cell).\n",
        "\n",
        "The file contains experimental results of an angular position vs. time (in seconds) for a damped oscillator.\n",
        "The first column is a list of times at which the measurements were made, the second column is the corresponding angular position.\n",
        "\n",
        "* Assign the first column of the loaded variable `a` to a new variable `t` (for time)\n",
        "* Assign the second column of the loaded variable `a` to a new variable `theta` (for angle)\n",
        "* Make a properly labeled plot of `theta` vs `t` (with units). \n",
        "* Given that it's experimental data, it's a good idea to plot points in addition to lines. This conveys how much/little data is available, and how closely-spaced it is.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_40ctGsLlP-X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pylab\n",
        "\n",
        "a = np.loadtxt('damped_oscillation.txt')\n",
        "print(type(a[0,0]))\n",
        "print(np.shape(a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDwasR4wlP-Y"
      },
      "outputs": [],
      "source": [
        "t     = a[:,0]\n",
        "theta = a[:,1]\n",
        "\n",
        "fig, ax = pylab.subplots(1,1)\n",
        "ax.plot(t, theta, 'o')\n",
        "ax.set_xlabel('time', fontsize=14)\n",
        "ax.set_ylabel('theta', fontsize=14)\n",
        "pylab.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading and writing text data files from GitHub"
      ],
      "metadata": {
        "id": "zSzDiwsxIrN0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSVZkxE-CCzX"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To query data files from GitHub, make sure to switch to Raw format on the website\n",
        "# This will clean out all the HTTP tags\n",
        "# Raw format\n",
        "url = 'https://raw.githubusercontent.com/lblogan14/CDSA2022_CompCourse/main/Day_09/damped_oscillation.txt'\n",
        "# HTTP rendered format\n",
        "#url = 'https://github.com/lblogan14/CDSA2022_CompCourse/blob/main/Day_09/damped_oscillation.txt'\n",
        "\n",
        "req = requests.get(url)\n",
        "raw_text = req.text\n",
        "print(raw_text)"
      ],
      "metadata": {
        "id": "DfLemrq8CFQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text.split('\\n')[2].split('\\t')"
      ],
      "metadata": {
        "id": "p9UqY4kPCmda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for substr in raw_text.split('\\n'):\n",
        "    if '#' in substr:\n",
        "        continue\n",
        "    else:\n",
        "        di = substr.split('\\t')\n",
        "        #print(di)\n",
        "        if len(di) < 2:\n",
        "            continue\n",
        "        else:\n",
        "            data.append(di)\n",
        "data = np.array(data, dtype=float)"
      ],
      "metadata": {
        "id": "UDixFZNtCRLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "9eS5u--XCh4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t     = data[:,0]\n",
        "theta = data[:,1]\n",
        "\n",
        "fig, ax = pylab.subplots(1,1)\n",
        "ax.plot(t, theta, 'o')\n",
        "ax.set_xlabel('time', fontsize=14)\n",
        "ax.set_ylabel('theta', fontsize=14)\n",
        "pylab.show()"
      ],
      "metadata": {
        "id": "MOXnXacRJRHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4UEXPdelP-Y"
      },
      "source": [
        "## Interacting with data\n",
        "\n",
        "Given our experimental data, we may want to extract something from it. For the damped oscillator data above, we might want to measure the frequency, amplitude, and damping coefficient.\n",
        "\n",
        "Often, we will want to know the functional relationship between these variables. In some cases, we may have a theoretical reason \n",
        "to expect a certain relationship between the variables; in other cases the data itself might suggest a type of functional \n",
        "relationship. \n",
        "\n",
        "Note that data will always contain experimental noise and have been measured with finite precision, causing the data points to be a bit scattered from a perfect line. \n",
        "\n",
        "We need a rational way determine the functional relationship between these variables; that is, we need a way to choose a function that best fits the scattered data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcCDzCY7lP-Z"
      },
      "source": [
        "Create a code that reads the freefall data and plots the speed versus time. Add the line $s = 9.8\\,t$ to \n",
        "the the graph, showing the behavior we should expect.\n",
        "\n",
        "Hint:* The data plot you plot in the exercise below should look something like this:\n",
        "![Data](http://www.physics.ncsu.edu/kemperlab/images/freefallgraph.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agMv7ucZlP-Z"
      },
      "outputs": [],
      "source": [
        "rdm_data = [[0.00,  -0.10290], \n",
        "            [0.10,   0.37364],\n",
        "            [0.20,   2.43748],\n",
        "            [0.30,   3.93836],\n",
        "            [0.40,   3.31230],\n",
        "            [0.50,   5.49472],\n",
        "            [0.60,   5.43325],\n",
        "            [0.70,   6.39321],\n",
        "            [0.80,   9.06048],\n",
        "            [0.90,   9.36415],\n",
        "            [1.00,   9.52066]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdm_data = np.array(rdm_data)\n",
        "t = rdm_data[:,0]\n",
        "speed = rdm_data[:,1]\n",
        "\n",
        "pylab.plot(t, speed, 'o')\n",
        "pylab.xlabel('time (s)', fontsize=14)\n",
        "pylab.ylabel('speed (m/s)', fontsize=14)\n",
        "pylab.show()"
      ],
      "metadata": {
        "id": "tpjCwD4aKPvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGY3P1YFlP-a"
      },
      "source": [
        "## Least Squares Fitting: Theory\n",
        "\n",
        "Often, we want to find the parameters of a function $f(x)$ that *best fits* the data. For instance, the slope of a line, or the frequency of an oscillator. \n",
        "\n",
        "Let $x_i$, $y_i$ denote the data, where $i = 1,\\ldots,N$ enumerates the individual data points (here, rows). \n",
        "\n",
        "We are looking for a function $f(x)$ that best fits this data. We will define *best fit* as the \n",
        "function that minimizes the sum of squares of differences between the function values $f(x_i)$ and the data\n",
        "values $y_i$ (this is not the only possible definition, as we will see below, but a very common one). Therefore, we define \n",
        "$$\n",
        "\tS = \\sum_{i=1}^N (f(x_i) - y_i)^2\n",
        "$$\n",
        "and look for the function $f(x)$ that minimizes $S$. This is called the *least squares* method, and $S$ is called the \"$L_2$-norm\". Note that the differences are squared so that \n",
        "each error contributes a positive \n",
        "amount to $S$. *To discuss:* can you see why this method has the name *least squares*?\n",
        "\n",
        "\n",
        "The first step is to guess the form of the function $f(x)$. For the problem above, where we know something about uniform graviational acceleration near the earth's surface, we might assume a linear relationship of the form $f(x) = ax + b$.  In that case, the  $L_2$ norm becomes\n",
        "$$\n",
        "\tS = \\sum_{i=1}^N (ax_i + b - y_i)^2\n",
        "$$\n",
        "\n",
        "Note that $S$ is a quadratic function of the fit parameters $a$ and $b$. The minimum of $S$ satisfies both\n",
        "\n",
        "$$\n",
        "    \\partial S/\\partial a = 0\\\\\n",
        "    \\partial S/\\partial b = 0\n",
        "$$\n",
        "\n",
        "where the partial derivative means that we take the derivative of only that variable. Note that we are treating $a$ and $b$ as variables because we want to see what moving them around does to the score $S$: the lower the score, the better the fit. \n",
        "\n",
        "If you take these two derivatives (do this for yourself on a piece of paper) these equations become:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\t\\sum(ax_i + b - y_i)x_i & = & 0 \\ \\\\\n",
        "\t\\sum(ax_i + b - y_i) & = & 0 \\ \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where we have dropped the limits on the summation signs for notational simplicity. \n",
        "\n",
        "Since $\\sum c = c N$ for any constant $c$, these two equations simplify to \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\ta\\sum x_i^2 \\, + \\, & b\\sum x_i & = & \\sum x_i y_i \\\\\n",
        "\ta\\sum x_i \\, + \\, & bN & = & \\sum y_i\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This is a system of linear equations for the two unknowns, $a$ and $b$. In matrix notation, \n",
        "we have \n",
        "$$\n",
        "\\begin{aligned}\n",
        "\t\\left( \\begin{array}{cc} \\sum x_i^2 & \\sum x_i \\\\\n",
        "\t\t\\sum x_i & N \\end{array} \\right) \\left( \\begin{array}{c} a \\\\ b \\end{array}\\right) \n",
        "\t= \\left( \\begin{array}{c} \\sum x_i y_i \\\\ \\sum y_i \\end{array}\\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "As you know from the previous less, you can find the solution using numpy's `solve()` function:\n",
        "\n",
        "    import numpy as n\n",
        "    A = n.matrix([[a11,a12],[a21,a22]])\n",
        "    r = n.matrix([[r1],[r2]])\n",
        "    soln = n.linalg.solve(A,r)\n",
        "    a = soln[0,0]\n",
        "    b = soln[1,0]\n",
        "\n",
        "with appropriate values used for the entries of `A` and `r`. \n",
        "\n",
        "\n",
        "### Other definitions of *best fit*\n",
        "Another reasonable approach, which is sometimes used, is based on the \"$L_1$-norm\". The $L_1$ norm is \n",
        "defined by $S = \\sum_{i=1}^N |f(x_i) - y_i|$. \n",
        "This is the *least absolute deviation* method of defining a best fit function. *To discuss:* can you think of a reason you might pick one method over the other?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXjHEDhlP-a"
      },
      "source": [
        "## Using least squares on a real dataset\n",
        "\n",
        "Now, let's pretend that we didn't know the value of $g$, and we wanted to use  the `freefall.data` dataset\n",
        "to find it. We do know enough to expect a linear relationship between speed $s$ and time $t$, and apart from \n",
        "experimental noise, and the data do seem to follow a linear trend. So our goal will be to find the straight \n",
        "line that comes closest to fitting the data. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build least-sqaure matrix\n",
        "A = np.identity(2)\n",
        "A[0,0]= np.sum(t**2)\n",
        "A[0,1]= np.sum(t)\n",
        "A[1,0]= np.sum(t)\n",
        "A[1,1]= len(t)\n",
        "r= np.matrix([[0.],[0.]])\n",
        "r[0,0]= np.sum(t*speed)\n",
        "r[1,0]= np.sum(speed)\n",
        "# Solve and build fit line\n",
        "soln = np.linalg.solve(A,r)\n",
        "a = soln[0,0]\n",
        "b = soln[1,0]\n",
        "yt= np.linspace(0, t[-1], 20)\n",
        "yy= a*yt+b"
      ],
      "metadata": {
        "id": "T1S4Idp7K1X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "pylab.plot(t, speed, 'o')\n",
        "pylab.plot(yt, yy, '--')\n",
        "pylab.xlabel('time (s)', fontsize=14)\n",
        "pylab.ylabel('speed (m/s)', fontsize=14)\n",
        "pylab.show()"
      ],
      "metadata": {
        "id": "dbPh4ML3K604"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S3WbP7xlP-a"
      },
      "source": [
        "## Least squarescurve-fitting with `scipy`\n",
        "\n",
        "As you may imagine, numpy has some of these routines already built-in.  Here we'll learn to use it.\n",
        "\n",
        "Least squares analysis can be applied to any function $f(x)$. For example, consider the data from \n",
        "the graph of the damped oscillator we made above.\n",
        "The data appear to follow a damped oscillator relationship, but we don't know the amplitude, frequency, phase, or damping coefficient. From what we know about damped oscillators, we think that the function \n",
        "\n",
        "$$\n",
        "\tf(t) = a\\cos(\\omega t + \\phi)  \\exp(-t/\\tau) + B\n",
        "$$\n",
        "\n",
        "would be a good fit. We can carry out a least-squares analysis to fit the `damped_oscillation.txt` data to a function of this form, and find the best-fit parameter values $a$, $\\omega$, $\\phi$, $\\tau$ and $B$ that minimize $S =  \\sum_{i=1}^N (a\\cos(\\omega t_i + \\phi)  \\exp(-t_i/\\tau) +B - y_i)^2$. \n",
        "\n",
        "This type of *curve fitting* is so useful that the module `scipy` includes the command `curve_fit` to carry out the \n",
        "analysis. You can import the command with \n",
        "\n",
        "    from scipy.optimize import curve_fit\n",
        "\n",
        "As usual, the documentation  (and a good example) is available online: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\n",
        "\n",
        "To use this command, you will first need to create a definition of the function we're going to use for the fit:\n",
        "\n",
        "    def func(t,a,omega,phi,tau,B):\n",
        "        return damped_oscillation_function_goes_here\n",
        "        \n",
        "The first argument is the independent variable `t`, and the remaining arguments \n",
        "are the parameters (in this case, $a$, $\\omega$, $\\phi$, $\\tau$, and $B). \n",
        "\n",
        "How do we use the scipy interface?\n",
        "Let's say the data are contained in arrays `xdata` and `ydata`. Then the command\n",
        "    \n",
        "    par, con = curve_fit(func,xdata,ydata)\n",
        "\n",
        "will return the best-fit values for $a$, $\\omega$, $\\phi$, $\\tau$ and $B$ in the parameter array `par`. \n",
        "\n",
        "*Optional:* If you are interested in the confidence you should place in these parameters, the array `con` contains \n",
        "further information about a type of error analysis that you should explore on your own (it's called the\n",
        "*covariance matrix*). \n",
        "\n",
        "Sometimes the `curve_fit` function does not converge to a result you expect, and you can nudge it along by\n",
        "providing a starting point for the fit through the optional parameter `p0`, where you can pass in an initial guess\n",
        "of parameters:\n",
        "\n",
        "    pguess = [guess_for_a, guess_for_omega, guess_for_phi, guess_for_tau, guess_for_B]\n",
        "    par, con = curve_fit(func, xdata, ydata, p0=pguess)\n",
        "\n",
        "You'll notice this may be necessary if the fitting routine complains: _RuntimeError: Optimal parameters not found_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpyAuQ0JlP-a"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Write a code that will import the data file `damped_oscillation.txt` (available on Google drive)\n",
        "and carry out a least-squares fit \n",
        "to a function of the form just discussed, using the scipy `curve_fit` function. Plot a graph showing the data points, as well as the best fit curve. What \n",
        "values did you get for the amplitude, frequency, phase and decay constant?  Annotate these on the plot, as well as the residual: $R^2 = \\sum_i (f(x_i) - y_i)^2$.\n",
        "\n",
        "*Stretch goal (optional):* include information about how you interpreted the errors, using the covariance matrix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import curve_fit\n",
        "###################\n",
        "# Main code\n",
        "###################\n",
        "# function to fit\n",
        "def func(time, a, omega, phi, tau, B):\n",
        "    return a*np.cos(omega*time + phi)*np.exp(-time/tau) + B\n",
        "\n",
        "# the osccilation data we read at the beginning of this notebook\n",
        "time = data[:, 0] # goes to time\n",
        "theta = data[:, 1] # goes to theta\n",
        "# scipy fit for least sqaure\n",
        "par, con = curve_fit(func, time, theta)\n",
        "# Output result for parameters. Make fit line\n",
        "a = par[0]\n",
        "omega = par[1]\n",
        "phi = par[2]\n",
        "tau = par[3]\n",
        "B = par[4]\n",
        "print(a, omega, phi, tau, B)\n",
        "yt= np.linspace(time[0], time[-1], 100)\n",
        "yy= func(yt, a, omega, phi, tau, B)"
      ],
      "metadata": {
        "id": "DksvFIaULGzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "pylab.plot(time, theta, 'x')\n",
        "pylab.plot(yt, yy, '-')\n",
        "pylab.xlabel('time (s)', fontsize=14)\n",
        "pylab.ylabel('theta (rad)', fontsize=14)\n",
        "pylab.show()"
      ],
      "metadata": {
        "id": "iykpxsXELY15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfitting, Underfitting, Model Complexity"
      ],
      "metadata": {
        "id": "6Hzli53dNtFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "def true_fun(X):\n",
        "    return np.cos(1.5 * np.pi * X)\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "n_samples = 30\n",
        "degrees = [1, 4, 15]\n",
        "\n",
        "X = np.sort(np.random.rand(n_samples))\n",
        "y = true_fun(X) + np.random.randn(n_samples) * 0.1"
      ],
      "metadata": {
        "id": "BsRpLU6YL6UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 5))\n",
        "for i in range(len(degrees)):\n",
        "    ax = plt.subplot(1, len(degrees), i + 1)\n",
        "    plt.setp(ax, xticks=(), yticks=())\n",
        "\n",
        "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
        "    linear_regression = LinearRegression()\n",
        "    pipeline = Pipeline(\n",
        "        [\n",
        "            (\"polynomial_features\", polynomial_features),\n",
        "            (\"linear_regression\", linear_regression),\n",
        "        ]\n",
        "    )\n",
        "    pipeline.fit(X[:, np.newaxis], y)\n",
        "\n",
        "    # Evaluate the models using crossvalidation\n",
        "    scores = cross_val_score(\n",
        "        pipeline, X[:, np.newaxis], y, scoring=\"neg_mean_squared_error\", cv=10\n",
        "    )\n",
        "\n",
        "    X_test = np.linspace(0, 1, 100)\n",
        "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
        "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
        "    plt.scatter(X, y, edgecolor=\"b\", s=20, label=\"Samples\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.xlim((0, 1))\n",
        "    plt.ylim((-2, 2))\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.title(\n",
        "        \"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
        "            degrees[i], -scores.mean(), scores.std()\n",
        "        )\n",
        "    )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sYiTqIDHNwoA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}